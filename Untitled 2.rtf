{\rtf1\ansi\ansicpg1252\cocoartf2706
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww16820\viewh15720\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 \
\
My interests lie at the intersection of two questions. The first question is: How can humans (and other animals to lesser extent) formulate and execute complex planning with multiple time-varying goals in dynamic environments?  The second question is: How do organisms justify their goals in a world of limitless possibilities, and where does value originate from that helps justify an intelligent agent\'92s choice to realize a potential state of the world?\
\
Both of these questions confront a difficult reality about intelligence which is that we have to cope with an exponentially larger space of possible dynamics.  Whether it be a state description of our internal states, the objects we possess, the state of the milk in the fridge or the level of gasoline is in your car.  Combining the set of state-spaces requires representing a Cartesian product space of possible states to understand their dynamics.\
\
However, much of the research done on planning in Artificial Intelligence is done under a paradigm called Reinforcement Learning (RL) assumes that normatively comes from agents desire to accumulate reward signals.  RL is a theory of learning that is based on what is called the Bellman Equations which is an equation that can be solved directly provided that we know the reward function and the agent\'92s dynamics in the world.  The issue is that Bellman Equations based on reward do not have natural decompositions over hierarchical spaces that allow us to break down complex problems into pieces so that we can stitch local solutions together to solve the global problem.  My research directly addresses this problem.  I develop and work with a class of Bellman equations called Operator Bellman Equations that, instead of producing value functions, produces abstract hierarchical transition operators factorizations that map the agent from it\'92s initial state to the final state of achieving a goal in the world.\
\
Because these Bellman equations produce hierarchical transition operator factorizations, the agent does not have to represent the product-space of the world, and instead can rapidly synthesize plans under challenging time-varying conditions.  Also, the agent can also apply a measure to }